# Glossary

This glossary defines key terms and constructs used throughout the Electric Barometer ecosystem.
Definitions are intentionally precise and operational in nature to ensure consistency across
documentation, code, and academic references.

---

## Electric Barometer

A framework for evaluating, comparing, and selecting forecasting systems based on the
*operational consequences* of forecast error rather than purely statistical accuracy.

Electric Barometer does not produce forecasts; it provides a structured method for assessing
how forecast errors translate into real-world costs under asymmetric conditions.

---

## Forecast

A quantitative estimate of a future value or event, typically generated by a statistical,
machine learning, or rules-based model.

Within Electric Barometer, a forecast is treated as an *input artifact* whose quality is
evaluated downstream based on operational impact.

---

## Forecast Error

The deviation between a forecasted value and the realized outcome.

Electric Barometer explicitly distinguishes between different *directions* and *magnitudes*
of forecast error when evaluating cost and risk.

---

## Asymmetric Error

A condition in which over-forecasting and under-forecasting result in *unequal operational
costs or consequences*.

Asymmetric error is central to many operational systems, such as inventory planning, labor
scheduling, and service capacity management.

---

## Cost Structure

A formal or implicit mapping between forecast error and operational cost.

Cost structures may be:
- Linear or non-linear
- Symmetric or asymmetric
- Continuous or threshold-based

Electric Barometer treats cost structures as first-class inputs to evaluation.

---

## Cost-Aware Evaluation

An approach to forecast evaluation that incorporates the operational cost of error rather
than relying solely on statistical error metrics (e.g., MAE, RMSE).

Cost-aware evaluation enables decision-making that aligns forecasting systems with real
business objectives.

---

## Cost-Weighted Loss

A loss formulation in which forecast errors are weighted according to their operational
impact.

Cost-weighted loss functions may be used for:
- Post-hoc evaluation
- Model selection
- Comparative analysis across forecasting systems

---

## Cost-Weighted Service Loss (CWSL)

A specific cost-weighted loss construct designed to quantify the operational impact of
forecast error in service-oriented environments.

CWSL emphasizes asymmetric penalties where under-forecasting and over-forecasting produce
different service outcomes.

---

## Forecast Readiness

A measure of how suitable a forecasting system is for deployment within a specific
operational context.

Forecast readiness reflects not only statistical performance, but also cost sensitivity,
risk tolerance, and decision alignment.

---

## Forecast Readiness Framework (FRF)

A structured framework for assessing forecasting systems based on readiness rather than
accuracy alone.

The FRF integrates cost structures, asymmetric loss, and operational constraints into a
coherent evaluation methodology.

---

## Readiness Adjustment

A transformation applied to forecast evaluation results to account for operational
conditions, tolerances, or risk preferences.

Readiness adjustments allow forecast comparisons to reflect real deployment environments
rather than idealized conditions.

---

## Tolerance Band

A defined range within which forecast error is considered operationally acceptable.

Tolerance bands may be asymmetric and are often derived from business constraints rather than
statistical considerations.

---

## Decision Quality

The degree to which decisions informed by a forecasting system produce favorable operational
outcomes.

Electric Barometer prioritizes decision quality over numerical accuracy when the two are in
conflict.

---

## Model Selection

The process of choosing one forecasting system from a set of candidates based on defined
evaluation criteria.

Within Electric Barometer, model selection is driven by cost-aware and readiness-oriented
metrics rather than traditional accuracy rankings.

---

## Adapter

A standardized interface layer that allows diverse forecasting engines or libraries to be
evaluated within a common framework.

Adapters abstract model-specific implementation details while preserving forecast behavior
and outputs.

---

## Evaluation Pipeline

The sequence of steps used to ingest forecasts, apply cost structures, compute loss, and
derive readiness measures.

Evaluation pipelines are designed to be reproducible, comparable, and extensible.

---

## Operational Context

The real-world environment in which a forecasting system is deployed, including constraints,
cost sensitivities, and risk tolerance.

Operational context determines how forecast errors are interpreted and penalized.

---

## Symmetric Metric

An evaluation metric that assigns equal weight or penalty to over-forecasting and
under-forecasting.

Symmetric metrics are often insufficient for operational decision-making but may be used for
baseline comparison.

---

## Economic Interpretation

The interpretation of forecast evaluation results in terms of cost, risk, and trade-offs
rather than abstract statistical measures.

Electric Barometer emphasizes economic interpretation to bridge analytics and operational
decision-making.

---

## Governance

The set of processes and controls used to approve, deploy, and monitor forecasting systems.

Cost-aware evaluation supports governance by making trade-offs explicit and auditable.

---

## Evaluation Artifact

Any structured output generated during the evaluation process, such as loss curves,
readiness scores, or comparative tables.

Evaluation artifacts are intended to support transparency and decision review.

---

## Ecosystem

The collection of packages, documentation, adapters, and methodologies that together
constitute the Electric Barometer framework.

The ecosystem is designed to be modular, extensible, and interoperable.

---
